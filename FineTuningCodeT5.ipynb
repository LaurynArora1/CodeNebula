{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1xr7ubFtUyt9VLtqhuAfnGQdrVo1fA3rO","authorship_tag":"ABX9TyMQ0hTXUr/zvWg6re/XxJrU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip show transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llExUrq4L5KD","executionInfo":{"status":"ok","timestamp":1709048535005,"user_tz":-330,"elapsed":10230,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}},"outputId":"691e9e73-509c-4bc7-f05c-3241bac2edc4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: transformers\n","Version: 4.38.1\n","Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n","Home-page: https://github.com/huggingface/transformers\n","Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n","Author-email: transformers@huggingface.co\n","License: Apache 2.0 License\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n","Required-by: \n"]}]},{"cell_type":"code","source":["!pip install transformers datasets sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3AYHPbN0EP-e","executionInfo":{"status":"ok","timestamp":1709048550191,"user_tz":-330,"elapsed":15192,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}},"outputId":"f551344b-7828-4797-860a-664ce54befdf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]}]},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, RobertaTokenizer, Trainer,TrainingArguments\n","from datasets import load_dataset\n","from transformers import TrainingArguments\n","from transformers import EarlyStoppingCallback\n","from transformers import Seq2SeqTrainer"],"metadata":{"id":"IpX3hr3dEdXt","executionInfo":{"status":"ok","timestamp":1709048565694,"user_tz":-330,"elapsed":15507,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"TVhFv3ypGU-y","executionInfo":{"status":"ok","timestamp":1709048565695,"user_tz":-330,"elapsed":22,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Load your dataset\n","data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/preprocessed_data (1).csv\")"],"metadata":{"id":"24FqL2KOEjKf","executionInfo":{"status":"ok","timestamp":1709048565695,"user_tz":-330,"elapsed":21,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Split data into training and validation sets (adjust test_size as needed)\n","test_size = 0.2\n","X_train, X_val, y_train, y_val = train_test_split(data[\"code\"],\n","                                                  data[\"summary\"],\n","                                                  test_size=test_size,\n","                                                  random_state=42)\n","train_df = pd.DataFrame({\"code\": X_train, \"summary\": y_train})\n","val_df = pd.DataFrame({\"code\": X_val, \"summary\": y_val})\n"],"metadata":{"id":"NklyIzNEGzTG","executionInfo":{"status":"ok","timestamp":1709048565695,"user_tz":-330,"elapsed":21,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model_name = \"Salesforce/codet5-base\"\n","tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0zpoi0vEw4V","executionInfo":{"status":"ok","timestamp":1709048568936,"user_tz":-330,"elapsed":3261,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}},"outputId":"b92ea9b0-0ca2-4ed7-943f-09bb0753afc1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}]},{"cell_type":"code","source":["# from transformers import TrainingArguments, EarlyStoppingCallback\n","# generation_config = {\n","#     \"max_length\": 128,\n","#     \"temperature\": 1.0,\n","#     \"top_k\": 50,\n","# }\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",  # Adjust the output directory\n","    per_device_train_batch_size=8,  # Adjust batch size as needed\n","    save_steps=5000,\n","    num_train_epochs=5,  # Adjust training epochs\n","    logging_steps=500,\n","    evaluation_strategy=\"epoch\",\n","    metric_for_best_model=\"bleu\",\n","\n",")\n","# Define EarlyStoppingCallback with desired patience\n","early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)\n","# Define custom compute metrics function for BLEU score\n","def compute_metrics(pred):\n","    label_ids, preds = pred\n","    pred_list = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    label_list = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","    bleu_score = sentence_bleu([[ref] for ref in label_list], pred_list)\n","    return {\"bleu\": bleu_score}\n"],"metadata":{"id":"dc5-Xp03E-e2","executionInfo":{"status":"ok","timestamp":1709048568937,"user_tz":-330,"elapsed":6,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["pip cache purge"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MUJkRhUHYal","executionInfo":{"status":"ok","timestamp":1709048569918,"user_tz":-330,"elapsed":986,"user":{"displayName":"Lauryn Arora","userId":"11174494345020422683"}},"outputId":"b3fdc711-5acc-47d0-8c6e-11af83e43c4e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Files removed: 1\n"]}]},{"cell_type":"code","source":["generation_config = {\n","    \"max_length\": 128,\n","    \"temperature\": 1.0,\n","    \"top_k\": 50,\n","}\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_df,\n","    eval_dataset=val_df,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n","    callbacks=[early_stopping_callback],\n","    generation_config=generation_config,\n","\n",")"],"metadata":{"id":"Ptule7pZFlLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"ajfaqI0TVmxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_pretrained(\"./fine-tuned_codet5\")  # Adjust the save path\n","tokenizer.save_pretrained(\"./fine-tuned_codet5\")\n"],"metadata":{"id":"iJ92njcXWEos"},"execution_count":null,"outputs":[]}]}